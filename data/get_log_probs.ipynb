{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from glob import glob\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leo/.pyenv/versions/3.12.0/lib/python3.12/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer\n",
    "import os\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.encoding_for_model(\"babbage-002\")\n",
    "\n",
    "def write_logprobs(text, file, model):\n",
    "    \"\"\"\n",
    "    Run text under model and write logprobs to file, separated by newline.\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.encode(text)\n",
    "    doc = tokenizer.decode(tokens[:2047])\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        model=model,\n",
    "        prompt=\"<|endoftext|>\" + doc,\n",
    "        max_tokens=0,\n",
    "        echo=True,\n",
    "        logprobs=1,\n",
    "    )\n",
    "\n",
    "    subwords = response[\"choices\"][0][\"logprobs\"][\"tokens\"][1:]\n",
    "    subprobs = response[\"choices\"][0][\"logprobs\"][\"token_logprobs\"][1:]\n",
    "\n",
    "    gpt2_map = {\"\\n\": \"Ċ\", \"\\t\": \"ĉ\", \" \": \"Ġ\"}\n",
    "\n",
    "    for i in range(len(subwords)):\n",
    "        for k, v in gpt2_map.items():\n",
    "            subwords[i] = subwords[i].replace(k, v)\n",
    "\n",
    "    to_write = \"\"\n",
    "    for _, (w, p) in enumerate(zip(subwords, subprobs)):\n",
    "        to_write += f\"{w} {-p}\\n\"\n",
    "\n",
    "    with open(file, \"w\") as f:\n",
    "        f.write(to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolders = [\"human\", \"gpt\", \"claude\", \"gpt_prompt1\", \"gpt_prompt2\", \"gpt_semantic\", \"gpt_writing\", \"back-trans/human\", \"back-trans/gpt\", \"synonym/human\", \"synonym/gpt\", \"emotion/gpt\", \"emotion/human\", \"style/gpt\", \"style/human\", \"summary/gpt\", \"summary/human\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** GETTING human LOG PROBS *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418ff761d9bb425e989a7dddb72dc66c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting log probs: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** GETTING gpt LOG PROBS *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "078703a146b140b08d22f05a81bfdd6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting log probs: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** GETTING claude LOG PROBS *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "404d6745ce4742a3ba1794a04b511245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting log probs: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** GETTING gpt_prompt1 LOG PROBS *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd517c90f80c4e2d840c18bcfa32c108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting log probs: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** GETTING gpt_prompt2 LOG PROBS *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf63c0982a2846cfac5c9d35a96f3bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting log probs: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** GETTING gpt_semantic LOG PROBS *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa599171cb54915b9116de30a4dfe2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting log probs: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** GETTING gpt_writing LOG PROBS *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5672123606154b2191311769f761af03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting log probs: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** GETTING back-trans/human LOG PROBS *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8be1c9e05c4201a06b126114526949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting log probs: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** GETTING back-trans/gpt LOG PROBS *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8877aec7502b4bd0afe971a5c15c9a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting log probs: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** GETTING synonym/human LOG PROBS *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57b8976651d843aebcf8143ab020c310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting log probs: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** GETTING synonym/gpt LOG PROBS *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28d955d180941f99d70836b11f1a50b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting log probs: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** GETTING emotion/gpt LOG PROBS *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9681683f4e84a478fee0a0acb6e617c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting log probs: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** GETTING emotion/human LOG PROBS *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344f3ec3d6b94fd096262fa4839a8cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting log probs: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** GETTING style/gpt LOG PROBS *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07bfaea2c1c4ec29b33f68ec5d71f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting log probs: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** GETTING style/human LOG PROBS *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae09f98e3ded418e950d8e806aeb4e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting log probs: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** GETTING summary/gpt LOG PROBS *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b00d6d6c0c54056ab1a873c83dc478a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting log probs: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** GETTING summary/human LOG PROBS *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1329b1f467845f48894aeebe4882c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting log probs: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for folder in subfolders:\n",
    "    print(f\"***** GETTING {folder} LOG PROBS *****\")\n",
    "    files = glob(f\"essay/{folder}/*.txt\")\n",
    "    files = sorted(files, key = lambda x: int(x.split(\"/\")[-1].split(\".\")[0]))\n",
    "    for i, file in tqdm(enumerate(files), desc = \"Getting log probs\"):\n",
    "        file_name = file.split(\"/\")[-1].split(\".\")[0]\n",
    "        with open(file) as f:\n",
    "            text = f.read()\n",
    "            if len(text) > 0:\n",
    "                ada_name = f\"essay/{folder}/logprobs/{file_name}-ada.txt\"\n",
    "                davinci_name = f\"essay/{folder}/logprobs/{file_name}-davinci.txt\"\n",
    "                if not os.path.isfile(ada_name):\n",
    "                    write_logprobs(text, f\"essay/{folder}/logprobs/{file_name}-ada.txt\", \"babbage-002\")\n",
    "                if not os.path.isfile(davinci_name):\n",
    "                    write_logprobs(text, f\"essay/{folder}/logprobs/{file_name}-davinci.txt\", \"davinci-002\")\n",
    "            else:\n",
    "                print(f\"EMPTY FILE AT {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
