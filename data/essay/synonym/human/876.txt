Although criminal activity in Reading, Pennsylvania, persisted high despite the city’s financial restrictions, police chief William Heim made a substantial investment in crime prognosis software in 2013. Prophetic Policing is the appellation of this Big Data commencement dubbed PredPol (abbreviated for prophetic policing). As assured, the software would scrutinize former crime statistics to pinpoint where and when offenses are most expected to happen hourly. The quantity of break-ins in high-crime districts plummeted by almost 20% when police commenced paying more attention to these focal points. Prophetic policing software is akin to numerous baseball statistical modeling. It is purportedly devoid of the racism and biases encompassed in the repeat offense models that the court system employs. For this software to function, it must possess ample data about the area to validate the presence of police there.
It has been confirmed that human endeavors create strain and jeopardy in susceptible populations. Arithmetical models currently dominate law enforcement. Due to theories that correlate nonviolent offenses to an increase in violent offenses, police chiefs believe that even “nuisance data” could be utilized to establish “superior data” that can focus more intensely on violent offenses. Police departments across the country are reinforcing zero-tolerance regulations for both violent and nonviolent transgressions by relying on statistics from prophetic policing approaches. One of the most perilous facets of this system is that its inner workings are shrouded from the general populace.
At a “hackathon” in the spring of 2011, O’Neil and the New York Civil Liberties Union collaborated to unearth vital insights on the NYPD’s controversial and damaging stop-and-frisk program. Numerous Black and Latino adolescents were being frisked because of data, despite the fact that merely 0.1% of those frisked were in any way linked to a severe offense. “Stop and Frisk,” O’Neil contends in his book, is not a WMD, but it employs mathematics to vindicate thousands of intrusive stops in vulnerable communities. Even though humans executed it, stop and frisk engendered horrendous feedback loops that disproportionately penalized Black and Latino males for minor infractions scarcely imposed on whites.
Police are inclined to aim for non-whites in low-income regions that lack access to exceptional schools and jobs. Consequently, sentencing recommendations grounded on WMDs, like prophetic policing and repeat offense models, are both racially biased and logically flawed. There is no regard for human behavior in these models that assert to possess a plethora of information on the probability that a former convict from a specific area would re-offend after being discharged from prison. According to O’Neil, justice system data analysts should comprehend penitentiary life and how it influences inmates’ behavior. Numerous inmates undergo malnourishment, solitary confinement, and sexual assault in prisons. When these facilities reach full capacity, they can spawn a $5 billion industry. When it comes to rendering prisons enigmatic, these companies go out of their way to do so.
In the not-too-distant future, facial recognition algorithms will be capable of identifying even more hazardous weapons of mass destruction. The Chicago Police Department visited a 22-year-old male who resided in a high-crime, low-income zone in 2013. They alerted him that the police were monitoring him because he was associated with persons who had been apprehended. By concentrating on individuals not engaged in criminal behavior, police were escalating racial tensions in the areas where criminal activity was rampant. According to O’Neil, formulating models that assume everyone is identical is more feasible than crafting policies that render the justice system more fair (though perhaps less effective).